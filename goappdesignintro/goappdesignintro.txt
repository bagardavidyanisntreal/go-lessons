С чего начать?

Данные советы будут полезны для архитектуры не только приложений на Go. Возможно, часть советов поможет сделать выбор и
с другим инструментарием.

Я бы хотел представить некую реализацию "чистой архитектуры" (ЧА), в рамках Go проекта или Go модуля. Данный подход навеян
изучением ЧА Боб Мартина (которая изначально была направлена на работу монолитных приложений), но в рамках микросервисов
и распределения нагрузок системы.

Ещё советую интересное видео с данным подходом от коллег:
 - https://youtu.be/V6lQG6d5LgU

Самое главное правило - всегда брать то, что действительно нужно: если выбор пал на "что-то", что-угодно (технологию,
паттерн, ещё один уровень абстракции, разделение, и прочее, прочее, прочее), то стоит задать несколько простых вопросов:

 - зачем это нужно?
 - что это решит?
 - можно ли обойтись без этого?
 - какие есть аналоги?
 - какая есть экспертиза?

И если на весах аргументов и фактов "что-то" новое проиграет, то следует смело проезжать мимо.

Итак, как уже можно догадаться, в Go, как и во многих других ЯП существует, по крайней мере, 2 больших лагеря:
 - монолитчики
 - микросервисники

На практике их куда больше и очень, очень часто понятия размываются, но по краям остаются моно и микро. Частенько на
практике можно встретить НЕ монолиты и НЕ микросервисы, а просто сервисы, ну или крайность, размазанные микросервисы, тн
наносервисы. Всё это происходит стихийно, и как правило, за бизнесом нужен глаз да глаз.

В чём же разница? Если грубо, то один микросервис может отвечать за один домен, например myowesomeecommerce.com/orders
Тогда как монолит владеет группой доменов, ну или поддоменов.

Немного о плюсах и минусах подходов.
В монолитном приложении достаточно удобно тестировать взаимодействие между модулями внутри, тк они находятся в рамках
одной кодовой базы, тогда как тн интеграционное тестирование микросервисов, а оно там становится именно таким, тк
функционал распределён в ряде доменов, становится почти что кошмаром для некоторых команд. Всё просто, когда функционал
далеко, то его сложнее достать или определить его поведение заготовленным сценарием (моками). В монолите это куда проще.

Идём далее, в монолите куда больше кода и зачастую контрибютеров, так что согласовать изменения становится сложнее чем в
микросервисах. Тебе приходится учитывать больше взаимодействия внутри, тк компоненты ближе и больше вероятности их связи.
Надеюсь вы, как и мы, используете статически типизированный язык или статический анализ, это слегка упростит жизнь, хотя
бы её часть.

Как бы микросервисы не пытались развязаться друг от друга, у них есть кое-что, что связывает их куда сильнее, чем просто
неявные связи в монолите, а именно, общие данные. Микросервисам приходится синхронизироваться, напрямую или асинхронно,
но это всегда проблема. Консистентность и согласованность данных из разных микросервисов, а эти данные так и норовят быть
размазаны.

Развёртывание или деплой, ну тут всё ясно, чем ты меньше - тем проще развернуться. То же самое касается массовых операций,
типа тестирования, проверок линтерами, переключения feature-toggles, и тд. Управлять проще чем-то маленьким и это правда.

Но есть сфера, в которой просто приходится становиться меньше, а именно горизонтальное масштабирование. Предположим что
есть интерфейс, который является фасадом для приёма заказов. Нам нужна хорошая пропускная способность и возможность
добавлять ресурсов для работы, если это потребуется. Поэтому мы выделяем эту сущность в некий order-facade, даём ему
нужный функционал для приёма заказов, причём так, чтобы на пути создания заказа было как можно меньше препятствий. Всё,
готово, можем запускать! Ресурс - это количество экземпляров этого order-facade чтобы мы не испытывали увеличения очереди
клиентов, тк они могут просто не дождаться своей очереди. Дальше просто надо организовать доставку этих данных для приготовления
заказов от клиентов и не забыть отправить их в ожидание. И тут очевидны плюсы микросервиса, он маленький, легко копируемый,
просто нужно согласовать работу в кластере и всё. С монолитом так легко просто не выйдет. Самое сложное в масштабировании
монолита, это организация взаимодействия в кластере, это всегда проблема.

Это был краткий экскурс в абстракции работы сервисов не только Go.

Теперь можно заглянуть поглубже. Как уже было сказано, стараться избегать "чего-то", не пройдя опросник выше и не взвесив
все за и против. Это нужно для:

 - удобства поддержки
 - масштабирования
 - тестирования
 - оптимизации
 - добавления нового функционала
 - изучения кодовой базы и тд

Теперь немного про тонкости самого Go как инструмента.

Абстракции.
Их нужно использовать грамотно. Прежде всего, абстракции помогают при тестировании кода, чуть реже, когда у вас получается
хорошее приложение, то вы можете заменять инструменты или компоненты, используя абстрактный интерфейс. Это бывает очень
полезно. Но, любая абстракция - это затрата. Не стоит просто так лепить интерфейс для абсолютно чего угодно или увидев
новый паттерн, добавить что-то новое и интересное. Прежде всего это замедлит time to market или delivery нового функционала.
Причём не только первоначально, но и в последующем. Будьте бдительны, не пропускайте случайную абстракцию, проводя код-ревью.

Реализацию абстракций в Go.
Существует подход с интерфейсами в месте использования и тн "пакетные интерфейсы". Я рекомендую использовать первый подход,
тк он будет способствовать избавлению от ненужного и с тз Go будет правильным: код будет всё больше и больше duck typed.

Например, мы пишем крон-сервис, который должен доставать данные из БД и что-то делать с ними или на их основе. Определим
интерфейс orderer в этом же пакете с кроном. Определим нужные методы у orderer, например
ListOrders(context.Context, *dto.ListOrderFilter) ([]*model.Order, error). Далее напишем или сгенерируем mock для этого
интерфейса в этом же пакете и, в целом, всё! Нам больше ничего не надо, мы можем смело использовать mock для составления
сценариев и тестирования нашего крона с множеством вариантов ответа от orderer. В конструктор крона мы отправим тот
самый репозиторий, у которого, помимо всего прочего, есть данный метод. Даже больше, если мы решим использовать
кеширующий репозиторий-обёртку или какой-то сторонний клиент, если наши заказы "уедут в другой сервис", мы всегда знаем
данный интерфейс и можем использовать его. Просто подменим реализацию в конструкторе и всё, это очень удобно.

По большей части, в Go принято использовать микросервисный подход. Из этого следует, что функционала в сервисе будет не
так много и он будет достаточно связан. Из этого я бы рекомендовал использовать "сквозные DTO" или "сквозные модели".
Дело тут вот в чём: пакетные дто могут быть полезны, но только если мы используем конкретную реализацию. Если же мы работаем
с абстракцией, то архитектурно неправильно использовать конкретные пакетные DTO/модели. Поэтому стоит озаботиться пакетом
и подпакетами (если это необходимо) для них.

Репозитории и хранилища данных.
Я стараюсь придерживаться подхода стандартизации работы с запросами и командами на изменение ресурса: любое хранилище
данных - это репозиторий. Да, безусловно, реализации бывают разными, реляционные бд, кеши, удалённые сервисы, даже
некоторые брокеры сообщений могут быть хранилищами данных, например те, которые хранят лог отправленных сообщений. Да,
все они работают по-разному, разные варианты подключения и передачи данных, разная скорость, но всё это репозитории.
Мы можем запросить или обновить данные в них. Поэтому стоит придерживаться единого подхода к запросам и командам в них,
для удобства их подмены или оборачивания (пример с кеширующим репозиторием). При всём при этом я рекомендую разделять их
на clients, repos и тд.

Internal.
Такой вот инструмент Go, позволяющий инкапсулировать некоторый функционал целого Go модуля, чтобы при его импорте, этот
функционал не был доступен. Это один из самых мощных инструментов программирования - инкапсуляция, но на уровне целого модуля.

Pkg.
Этот пакет используется как раз наоборот для того что хочется "отдать наружу", а через него уже может быть осуществлено
взаимодействие с go модулем. Не советую класть pkg в internal, тк учёные до сих пор спорят о природе этого явления.

Работа с сущностями.
В проектах как с ORM, так и без них часто возникают сущности, модели или dto или даже все эти элементы частично или сразу.
Это нормально. Существует несколько признаков того что ваша сущность DTO или модель:

 - DTO: не имеет инкапсуляции и поведения, открыта для юзкейсов
 - Модель: имеет инкапсуляцию, поведение и даже состояние. Существует также варианты с иммутабельным (неизменяемым) состоянием

Что использовать - решать уже вам самому, разница есть, она очевидна, но свои преимущества есть в обоих подходах. Например,
ДТО может быть переиспользована во множестве сценариев или функциях, тогда как модельки плодятся от типа к типу достаточно
быстно. За то модельки лучше управляют состоянием, но на их содержание уходит больше времени, тогда как с ДТО может
возникнуть больше проблем, при "неучтёнке" юзкейса, решать, конечно, вам.
